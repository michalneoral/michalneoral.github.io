---
layout: page
permalink: /publications/
title: Publications
---

<h2>Main Publications</h2>
<ul>
	<li>
		<b>Multi-Flow Tracker with Independent Matching Quality Estimation</b><br>
		<i>Jonáš Šerých, <b>Michal Neoral</b>, and Jiří Matas</i><br>
		Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, February 2025, Tuscon, Arizona USA.<br>
		<a href="https://openaccess.thecvf.com/content/WACV2025/papers/Serych_MFTIQ_Multi-Flow_Tracker_with_Independent_Matching_Quality_Estimation_WACV_2025_paper.pdf"><div class="color-button">pdf</div></a>
        <a href="https://arxiv.org/abs/2411.09551"><div class="color-button">arXiv</div></a>
        <a href="https://openaccess.thecvf.com/content/WACV2025/supplemental/Serych_MFTIQ_Multi-Flow_Tracker_WACV_2025_supplemental.pdf"><div class="color-button">supplementary</div></a>
        <a href="https://github.com/serycjon/MFTIQ"><div class="color-button">code</div></a>
        <a href="https://cmp.felk.cvut.cz/~serycjon/MFTIQ/"><div class="color-button">project page</div></a>
	</li><br>
	<li>
		<b>MFT: Long-term Tracking of Every Pixel</b><br>
		<i><b>Michal Neoral</b>, Jonáš Šerých, and Jiří Matas</i><br>
		Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pp. 6837–6847, January 2024, Waikoloa, Hawaii USA. <br>
        <a href="https://openaccess.thecvf.com/content/WACV2024/papers/Neoral_MFT_Long-Term_Tracking_of_Every_Pixel_WACV_2024_paper.pdf"><div class="color-button">pdf</div></a>
        <a href="https://arxiv.org/abs/2305.12998"><div class="color-button">arXiv</div></a>
        <a href="https://openaccess.thecvf.com/content/WACV2024/supplemental/Neoral_MFT_Long-Term_Tracking_WACV_2024_supplemental.zip"><div class="color-button">supplementary</div></a>
        <a href="https://github.com/serycjon/MFT"><div class="color-button">code</div></a>
        <a href="https://cmp.felk.cvut.cz/~serycjon/MFT/"><div class="color-button">project page</div></a>
	</li><br>
    <li>
		<b>Monocular Arbitrary Moving Object Discovery and Segmentation</b><br>
		<i><b>Michal Neoral</b>, Jan Šochman, and Jiří Matas</i><br>
		In The 32nd British Machine Vision Conference, November 2021, Online. <br>
        <a href="https://www.bmvc2021-virtualconference.com/assets/papers/1500.pdf"><div class="color-button">pdf</div></a>
        <a href="https://github.com/michalneoral/Raptor"><div class="color-button">code</div></a>
	</li><br>
    <li>
		<b>Continual Occlusion and Optical Flow Estimation</b><br>
		<i><b>Michal Neoral</b>, Jan Šochman, and Jiří Matas</i><br>
		Computer Vision – ACCV 2018. Ed. by C.V. Jawahar et al. Cham: Springer International Publishing, 2019, pp. 159–174. ISBN: 978-3-030-20870-7. <br>
        <a href="https://link.springer.com/chapter/10.1007/978-3-030-20870-7_10"><div class="color-button">pdf</div></a>
        <a href="https://arxiv.org/abs/1811.01602"><div class="color-button">arXiv</div></a>
	</li><br>
    <li>
		<b>Object Scene Flow with Temporal Consistency</b><br>
		<i><b>Michal Neoral</b>, and Jan Šochman</i><br>
		In 22nd Computer Vision Winter Workshop (CVWW) Pattern Recognition and Image Processing Group; TU Wien \& PRIP Club; Vienna; Austria, February 2017, ISBN: 978-3-200-04969-7. <br>
        <a href="https://cvww2017.prip.tuwien.ac.at/papers/CVWW2017_paper_27.pdf"><div class="color-button">pdf</div></a>
	</li><br>
</ul>

<h2>Other Publications</h2>
<ul>
	<li>
		<b>Point Tracking in Surgery–The 2024 Surgical Tattoos in Infrared (STIR) Challenge</b><br>
		<i>Adam Schmidt, Mert Asim Karaoglu, Soham Sinha, Mingang Jang, Ho-Gun Ha, Kyungmin Jung, Kyeongmo Gu, Ihsan Ullah, Hyunki Lee, Jonáš Šerých, <b>Michal Neoral</b>, Jiří Matas, Rulin Zhou, Wenlong He, An Wang, Hongliang Ren, Bruno Silva, Sandro Queiros, Estevao Lima, Joao L. Vilac, Shunsuke Kikuchi, Atsushi Kouno, Hiroki Matsuzaki, Tongtong Li, Yulu Chen, Ling Li, Xiang Ma, Xiaojian Li, Mona Sheikh Zeinoddin, Xu Wang, Zafer Tandogdu, Greg Shaw, Evangelos Mazomenos, Danail Stoyanov, Yuxin Chen, Zijian Wu, Alexander Ladikos, Simon DiMaio, Septimiu E. Salcudean, and Omid Mohareri</i><br>
		<a href="https://arxiv.org/pdf/2503.24306"><div class="color-button">pdf</div></a>
        <a href="https://arxiv.org/abs/2503.24306"><div class="color-button">arXiv</div></a>
        <a href="https://stir-challenge.github.io/"><div class="color-button">project page</div></a>
	</li><br>
</ul>

<h2>Theses</h2>
<ul>
    <li>
		<b>Dense Motion Estimation in a Monocular Video</b><br>
		<b>Michal Neoral</b>, supervisor: prof. Ing. Jiří Matas, Ph.D., co-supervisor: Mgr. Jan Šochman, Ph.D.<br>
        2025 <b>Dissertation</b>, in review process
    </li><br>
	<li>
		<b>Object Scene Flow in Video Sequences</b><br>
		<b>Michal Neoral</b>, supervisor: Mgr. Jan Šochman, Ph.D.<br>
        2017 <b>Master Thesis</b>, awarded with the Dean's Prize for outstanding master thesis.
    </li><br>
	<li>
		<b>Extraction of Features from Moving Garment</b><br>
		<b>Michal Neoral</b>, supervisor: Ing. Pavel Krsek, Ph.D.<br>
        2014 <b>Bachelor Thesis</b>.
    </li><br>
</ul>



<h2>Patents and Patent Applications</h2>
<ul>
	<li>
		<b>MONOCULAR-VISION-BASED DETECTION OF MOVING OBJECTS</b><br>
		<i>Nikolay Chumerin, <b>Michal Neoral</b>, Jan Šochman, and Jiří Matas (2023).</i><br>
        EP Patent EP4174770B1, filed Oct 28, 2021, and issued Nov 29, 2023. <b>Granted Patent</b>
    </li><br>
	<li>
		<b>A METHOD AND SYSTEM FOR TRACKING A PIXEL IN A VIDEO</b><br>
		<i>Nikolay Chumerin, Jonáš Šerých, <b>Michal Neoral</b>, and Jiří Matas. (2024).</i><br>
        EP Patent EP4465239A1, filed May 16, 2023, and issued Nov 20, 2024. <b>Patent Application</b>
    </li><br>
    <li>
		<b>MONOCULAR-VISION-BASED DETECTION OF MOVING OBJECTS</b><br>
		<i>Nikolay Chumerin, <b>Michal Neoral</b>, Jan Šochman, and Jiří Matas. (2023).</i><br>
        EP Patent EP4174770A1, filed Oct 28, 2021, and issued May 03, 2023. <b>Patent Application</b>
    </li><br>
    <li>
		<b>METHODS FOR OPTICAL FLOW ESTIMATION</b><br>
		<i>Jan Šochman, Nikolay Chumerin, Jiří Matas, and <b>Michal Neoral</b>. (2020).</i><br>
        WO Patent WO2020088766A1, filed Oct 31, 2018, and issued May 07, 2020. <b>Patent Application</b>
    </li><br>
</ul>


[//]: # (<h2>Research Projects</h2>)

[//]: # (<ul>)

[//]: # (	<li>)

[//]: # (		<b>Project title</b><br>)

[//]: # (		University, Duration<br>)

[//]: # (		<i>Other details such as advisor's name may go here</i><br>)

[//]: # (		<a href=""><div class="color-button">report</div></a><a href=""><div class="color-button">code</div></a>)

[//]: # (	</li><br>)

[//]: # (	<li>)

[//]: # (		<b>Project title</b><br>)

[//]: # (		University, Duration<br>)

[//]: # (		<i>Other details such as advisor's name may go here</i><br>)

[//]: # (		<a href=""><div class="color-button">report</div></a><a href=""><div class="color-button">code</div></a>)

[//]: # (	</li><br>)

[//]: # (</ul>)

[//]: # ()
[//]: # (<h2>Research Implementations</h2>)

[//]: # (<ul>)

[//]: # (	<li>)

[//]: # (		<b>Title #1</b>: Brief description of this research implementation.<br>)

[//]: # (		<a href=""><div class="color-button">paper</div></a><a href=""><div class="color-button">report</div></a><a href=""><div class="color-button">code</div></a>)

[//]: # (	</li><br>)

[//]: # (	<li>)

[//]: # (		<b>Title #2</b>: Brief description of this research implementation.<br>)

[//]: # (		<a href=""><div class="color-button">paper</div></a><a href=""><div class="color-button">report</div></a><a href=""><div class="color-button">code</div></a>)

[//]: # (	</li><br>)

[//]: # (</ul>)


